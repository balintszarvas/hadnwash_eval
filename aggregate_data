import pandas as pd
import numpy as np
from pathlib import Path

# Initial setup
BASE_PATH = Path("raw_data")
LABELS = ["One", "Two", "Three", "Four", "Five"]
SENSORS = {
    "Accelerometer.csv": "acc_",
    "Linear Accelerometer.csv": "linacc_",
    "Gyroscope.csv": "gyr_",
    "Magnetometer.csv": "mag_"
}

GRANULARITY = '250ms'
START_DATETIME = pd.to_datetime("2025-01-01 00:00:00")

all_data = []
time_offset = pd.to_timedelta(0)

# Function to load and aggregate sensor data
def load_and_aggregate_sensor(file_path, prefix, offset):
    df = pd.read_csv(file_path)

    if "Time (s)" not in df.columns:
        raise ValueError(f"'Time (s)' column not found in {file_path}")

    # Add offset so time continues
    df['timestamp'] = START_DATETIME + offset + pd.to_timedelta(df["Time (s)"], unit='s')
    df = df.set_index('timestamp')
    df = df.drop(columns=["Time (s)"])
    df = df.rename(columns=lambda col: prefix + col.strip().split(" ")[0].lower())
    return df.resample(GRANULARITY).mean()

# Loop through each label and process sensors
for label in LABELS:
    print(f"Processing label: {label}")
    folder_path = BASE_PATH / label
    dfs = []

    # Determine duration of this label block from a reference sensor
    ref_file = folder_path / "Accelerometer.csv"
    duration = pd.read_csv(ref_file)["Time (s)"].max()

    # Process each sensor with current offset
    for sensor_file, prefix in SENSORS.items():
        file_path = folder_path / sensor_file
        sensor_df = load_and_aggregate_sensor(file_path, prefix, time_offset)
        dfs.append(sensor_df)

    # Merge sensors on timestamp
    merged = pd.concat(dfs, axis=1)

    # Add label columns (one-hot encoded)
    for lbl in LABELS:
        merged[f"label{lbl}"] = 1 if lbl == label else 0

    # Add to final dataset
    all_data.append(merged)

    # Update time offset for the next block
    time_offset += pd.to_timedelta(duration, unit="s")

# Concatenate all label dataframes into one 
final_df = pd.concat(all_data).reset_index()
final_df = final_df.rename(columns={'timestamp': 'datetime'})

# Forward-fill NaN values in sensor columns
sensor_cols = [col for col in final_df.columns if col.startswith(('acc_', 'linacc_', 'gyr_', 'mag_'))]
fill_nan_rows = final_df[sensor_cols].isna().all(axis=1)
final_df.loc[fill_nan_rows, sensor_cols] = final_df[sensor_cols].ffill().loc[fill_nan_rows]

# Save the final dataset
final_df.to_csv(f"handwash_{GRANULARITY}.csv", index=False)
print(f"Dataset saved as 'handwash_{GRANULARITY}.csv'")